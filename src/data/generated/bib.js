define({ entries : {
    "acharya2022contrastive": {
        "abstract": "Applies contrastive learning principles to PU learning. Proposes PU contrastive loss to enhance representation learning in unsupervised settings and better separate positives from negatives.",
        "author": "Acharya, Aditya and Sanghavi, Sujay and Jing, Li and Bhushanam, Bhuvana and Choudhary, Divyanshu and Rabbat, Michael and Dhillon, Inderjit",
        "booktitle": "Proc. Int. Conf. Mach. Learn. (ICML)",
        "keywords": "type:method, PU_learning, contrastive_learning, representation_learning, self_supervised, category:deep-learning",
        "title": "Positive Unlabeled Contrastive Learning",
        "type": "inproceedings",
        "url": "https://arxiv.org/abs/2206.01206",
        "year": "2022"
    },
    "bekker2020survey": {
        "abstract": "Comprehensive survey of PU learning covering definitions, scenarios, taxonomy (two-step vs. risk-based), and real-world applications. Highlights challenges and potential in incomplete label settings.",
        "author": "Bekker, Jesse H. Krijthe and Davis, Jesse",
        "doi": "10.1007/s10994-020-05877-5",
        "journal": "Machine Learning",
        "keywords": "type:survey, PU_learning, risk_estimation, weak_supervision, label_incompleteness, category:survey",
        "pages": "719--760",
        "title": "Learning from Positive and Unlabeled Data: A Survey",
        "type": "article",
        "url": "https://doi.org/10.1007/s10994-020-05877-5",
        "volume": "109",
        "year": "2020"
    },
    "chang2016streamingPU": {
        "abstract": "Proposes an online PU learning algorithm for streaming graph data, able to dynamically adapt to data drift and efficiently identify hidden negative samples. Demonstrates real-time prediction capability on large-scale networks.",
        "author": "Chang, Shiyu and Zhang, Yu and Tang, Jiliang and Yin, Dawei and Chang, Yi and Hasegawa-Johnson, Mark and Huang, Thomas S.",
        "booktitle": "Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD)",
        "doi": "10.1145/2939672.2939744",
        "keywords": "type:method, PU_learning, graph_mining, streaming_data, category:online-learning",
        "pages": "755--764",
        "title": "Positive-Unlabeled Learning in Streaming Networks",
        "type": "inproceedings",
        "url": "https://doi.org/10.1145/2939672.2939744",
        "year": "2016"
    },
    "coudray2023riskBounds": {
        "abstract": "Analyzes PU learning under the \"selected at random\" (SAR) assumption. Provides theoretical risk bounds and studies the impact of sample selection bias, contributing to foundational understanding of PU risk estimators.",
        "author": "Coudray, Olivier and Keribin, Caroline and Massart, Pascal and Pamphile, Philippe",
        "journal": "Journal of Machine Learning Research",
        "keywords": "type:theory, PU_learning, risk_bounds, SAR_assumption, statistical_learning, category:theory",
        "pages": "1--39",
        "title": "Risk Bounds for Positive-Unlabeled Learning Under the Selected At Random Assumption",
        "type": "article",
        "url": "https://www.jmlr.org/papers/v24/22-067.html",
        "volume": "24",
        "year": "2023"
    },
    "jaskie2019survey": {
        "abstract": "Surveys PU learning techniques with an emphasis on their application to real-world domains such as healthcare and information retrieval. Discusses benefits, limitations, and deployment challenges.",
        "author": "Jaskie, Kyle and Spanias, Andreas",
        "booktitle": "Proc. IEEE Int. Conf. Acoust., Speech and Signal Processing (ICASSP)",
        "keywords": "type:survey, PU_learning, applications, healthcare, information_retrieval, category:survey",
        "title": "Positive-Unlabeled Learning Algorithms and Applications: A Survey",
        "type": "inproceedings",
        "url": "https://www.researchgate.net/publication/337503578_Positive_And_Unlabeled_Learning_Algorithms_And_Applications_A_Survey",
        "year": "2019"
    },
    "kiryo2017nnpu": {
        "abstract": "Introduces the non-negative risk estimator (nnPU) to resolve negative empirical risk issues in PU learning. Proves theoretical guarantees and shows improved robustness and classification performance.",
        "author": "Kiryo, Ryuichi and Niu, Gang and du Plessis, Makoto C. and Sugiyama, Masashi",
        "booktitle": "Proc. Adv. Neural Inf. Process. Syst. (NeurIPS)",
        "keywords": "type:method, PU_learning, risk_estimation, non_negative_risk, theoretical_guarantee, category:theory",
        "title": "Positive-Unlabeled Learning with Non-Negative Risk Estimator",
        "type": "inproceedings",
        "url": "https://papers.nips.cc/paper_files/paper/2017/hash/7cce53cf90577442771720a370c3c723-Abstract.html",
        "year": "2017"
    },
    "long2024metaDisambiguation": {
        "abstract": "Proposes a meta-disambiguation method that models implicit group structures in data to better identify false negative samples in PU learning. Improves accuracy in noisy environments.",
        "author": "Long, Linyuan and Wang, Hongda and Jiang, Ziyu and Feng, Linfeng and Yao, Chengwei and Chen, Guanting and Zhao, Junbo",
        "booktitle": "Proc. IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR)",
        "keywords": "type:method, PU_learning, meta_learning, latent_groups, disambiguation, category:sample-selection",
        "title": "Positive-Unlabeled Learning by Latent Group-Aware Meta Disambiguation",
        "type": "inproceedings",
        "url": "https://openaccess.thecvf.com/content/CVPR2024/papers/Long_Positive-Unlabeled_Learning_by_Latent_Group-Aware_Meta_Disambiguation_CVPR_2024_paper.pdf",
        "year": "2024"
    },
    "luo2021negativesampler": {
        "abstract": "Presents a negative sample selector to enhance pseudo-negative mining in PU learning. Demonstrates effectiveness in improving classification across multiple benchmark datasets.",
        "author": "Luo, Chuan and Zhao, Peng and Chen, Chen and Qiao, Bin",
        "booktitle": "Proc. AAAI",
        "keywords": "type:method, PU_learning, pseudo_negatives, classification, category:sample-selection",
        "title": "Positive-Unlabeled Learning with Effective Negative Sample Selector",
        "type": "inproceedings",
        "url": "https://ojs.aaai.org/index.php/AAAI/article/view/17064",
        "year": "2021"
    },
    "tang2022adversarialKG": {
        "abstract": "Combines adversarial data augmentation with PU learning for knowledge graph completion. Introduces perturbation strategies to enhance generalization and mitigate overfitting on sparse unlabeled data.",
        "author": "Tang, Zhenyu and Pei, Shuangjun and Zhang, Ziqing and Zhu, Yukun and Zhuang, Fei and Hoehndorf, Robert and Zhang, Xiangliang",
        "booktitle": "Proc. AAAI",
        "keywords": "type:application, PU_learning, adversarial_learning, knowledge_graphs, generalization, category:deep-learning",
        "title": "Positive-Unlabeled Learning with Adversarial Data Augmentation for Knowledge Graph Completion",
        "type": "inproceedings",
        "url": "https://arxiv.org/abs/2205.00904",
        "year": "2022"
    },
    "zhu2023selfcorrection": {
        "abstract": "Proposes a self-correcting mechanism to handle label noise in negative samples. Adjusts pseudo-labels adaptively, improving robustness of PU classifiers under high-noise conditions.",
        "author": "Zhu, Zhangchi and Wang, Li and Zhao, Peng and Du, Cheng and Zhang, Wenjun",
        "booktitle": "Proc. ACM Int. Conf. Inf. Knowl. Manage. (CIKM)",
        "keywords": "type:method, PU_learning, label_noise, self_correction, robust_classification, category:sample-selection",
        "title": "Robust Positive-Unlabeled Learning via Noise Negative Sample Self-correction",
        "type": "inproceedings",
        "url": "https://arxiv.org/abs/2308.00279",
        "year": "2023"
    }
}});
